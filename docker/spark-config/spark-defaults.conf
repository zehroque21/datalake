# Spark configuration for Delta Lake
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true

# Delta Lake specific configurations
spark.databricks.delta.retentionDurationCheck.enabled=false
spark.databricks.delta.vacuum.parallelDelete.enabled=true

# Memory settings for local development
spark.driver.memory=1g
spark.executor.memory=1g
spark.driver.maxResultSize=512m

# Logging
spark.sql.adaptive.logLevel=WARN

